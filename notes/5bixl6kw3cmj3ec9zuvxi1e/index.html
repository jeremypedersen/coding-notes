<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="icon" href="/coding-notes/favicon.ico"/><title>Hardware</title><meta name="robots" content="index,follow"/><meta name="googlebot" content="index,follow"/><meta name="description" content="Hardware"/><meta property="og:title" content="Hardware"/><meta property="og:description" content="Hardware"/><meta property="og:url" content="https://jeremypedersen.github.io/coding-notes/notes/5bixl6kw3cmj3ec9zuvxi1e/"/><meta property="og:type" content="article"/><meta property="article:published_time" content="3/14/2024"/><meta property="article:modified_time" content="4/16/2024"/><link rel="canonical" href="https://jeremypedersen.github.io/coding-notes/notes/5bixl6kw3cmj3ec9zuvxi1e/"/><meta name="next-head-count" content="14"/><link rel="preload" href="/coding-notes/_next/static/css/b0c7e77ce5f99436.css" as="style"/><link rel="stylesheet" href="/coding-notes/_next/static/css/b0c7e77ce5f99436.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/coding-notes/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/coding-notes/_next/static/chunks/webpack-eed3f0eedf802397.js" defer=""></script><script src="/coding-notes/_next/static/chunks/framework-28c999baf2863c3d.js" defer=""></script><script src="/coding-notes/_next/static/chunks/main-29387b2bb14b1eb7.js" defer=""></script><script src="/coding-notes/_next/static/chunks/pages/_app-dc4bb01b71d58e47.js" defer=""></script><script src="/coding-notes/_next/static/chunks/935-4dee79e80b8641c6.js" defer=""></script><script src="/coding-notes/_next/static/chunks/6-50972def09142ee2.js" defer=""></script><script src="/coding-notes/_next/static/chunks/pages/notes/%5Bid%5D-78d472fa3b924116.js" defer=""></script><script src="/coding-notes/_next/static/jdQmoR0T7zxn3zBS6JrtA/_buildManifest.js" defer=""></script><script src="/coding-notes/_next/static/jdQmoR0T7zxn3zBS6JrtA/_ssgManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><section class="ant-layout" style="width:100%;min-height:100%"><header class="ant-layout-header" style="position:fixed;isolation:isolate;z-index:1;width:100%;border-bottom:1px solid #d4dadf;height:64px;padding:0 24px 0 2px"><div class="ant-row ant-row-center" style="max-width:992px;justify-content:space-between;margin:0 auto"><div style="display:flex" class="ant-col ant-col-xs-20 ant-col-sm-4"></div><div class="ant-col gutter-row ant-col-xs-0 ant-col-sm-20 ant-col-md-20 ant-col-lg-19"><div class="ant-select ant-select-lg ant-select-auto-complete ant-select-single ant-select-allow-clear ant-select-show-search" style="width:100%"><div class="ant-select-selector"><span class="ant-select-selection-search"><input type="search" autoComplete="off" class="ant-select-selection-search-input" role="combobox" aria-haspopup="listbox" aria-owns="undefined_list" aria-autocomplete="list" aria-controls="undefined_list" aria-activedescendant="undefined_list_0" value=""/></span><span class="ant-select-selection-placeholder">For full text search please use the &#x27;?&#x27; prefix. e.g. ? Onboarding</span></div></div></div><div style="display:none;align-items:center;justify-content:center" class="ant-col ant-col-xs-4 ant-col-sm-4 ant-col-md-0 ant-col-lg-0"><span role="img" aria-label="menu" style="font-size:24px" tabindex="-1" class="anticon anticon-menu"><svg viewBox="64 64 896 896" focusable="false" data-icon="menu" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M904 160H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0 624H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0-312H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8z"></path></svg></span></div></div></header><section class="ant-layout" style="margin-top:64px;display:flex;flex-direction:row"><div class="site-layout-sidebar" style="flex:0 0 auto;width:calc(max((100% - 992px) / 2, 0px) + 200px);min-width:200px;padding-left:calc((100% - 992px) / 2)"><aside class="ant-layout-sider ant-layout-sider-dark" style="position:fixed;overflow:auto;height:calc(100vh - 64px);background-color:transparent;flex:0 0 200px;max-width:200px;min-width:200px;width:200px"><div class="ant-layout-sider-children"></div></aside></div><main class="ant-layout-content side-layout-main" style="max-width:1200px;min-width:0;display:block"><div style="padding:0 24px"><div class="main-content" role="main"><div class="ant-row"><div class="ant-col ant-col-24"><div class="ant-row" style="margin-left:-10px;margin-right:-10px"><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-24 ant-col-md-18"><div><h1 id="hardware">Hardware<a aria-hidden="true" class="anchor-heading icon-link" href="#hardware"></a></h1>
<p>This section talks about the different hardware configurations which can be used to run ML models. </p>
<p>To avoid having this section explode to cover every recent version of every piece of hardware from every major vendor, we will try to focus on newer hardware, and on very large models like <a href="https://huggingface.co/docs/diffusers/en/using-diffusers/sdxl">SDXL</a> or <a href="https://huggingface.co/meta-llama">Llama 2</a>, which are large enough that compute and memory constraints come into play even on new hardware.</p>
<p>For each piece of hardware we will try to address the following questions:</p>
<ul>
<li>What is its general type? 
<ul>
<li>CPU</li>
<li>GPU</li>
<li>FPGA</li>
<li>Something else</li>
</ul>
</li>
<li>What is its architecture? 
<ul>
<li>ARM</li>
<li>x86</li>
<li>Something else</li>
</ul>
</li>
<li>Where is it available? 
<ul>
<li>Cloud
<ul>
<li>Which provider?</li>
<li>Which regions?</li>
</ul>
</li>
<li>Local</li>
</ul>
</li>
<li>What data types are supported? 
<ul>
<li>FLOAT32</li>
<li>FLOAT16</li>
<li>BFLOAT16</li>
<li>INT8</li>
<li>Others</li>
</ul>
</li>
<li>AI Acceleration features? 
<ul>
<li>OpenVINO toolkit (Intel)</li>
<li>Advanced Matrix Extensions (AMX - Intel)</li>
<li>Neuron (AWS Inferentia SDK)</li>
</ul>
</li>
<li>What does it cost?
<ul>
<li>Hourly</li>
<li>Yearly (for providers with up-front pricing options)</li>
<li>Fixed cost (for local hardware)</li>
</ul>
</li>
<li>How well does it perform? 
<ul>
<li>Inference and fine-tuning speeds</li>
<li>Inferences-per-second</li>
<li>Cost-per-inference</li>
</ul>
</li>
</ul>
<p>To try to keep things organized, we will sort hardware into two general categories:</p>
<ol>
<li>Cloud: hardware available from major cloud providers.</li>
<li>Edge: hardware you run yourself locally.</li>
</ol>
<p>This scheme results in some overlap as most of the hardware available through the major cloud providers will overlap, but it means we get to see differences in pricing and regional availability by provider. It also separates out consumer hardware intended to be used and purchased by individuals from server hardware (which is what the cloud companies buy and/or build). </p>
<h3 id="edge">Edge<a aria-hidden="true" class="anchor-heading icon-link" href="#edge"></a></h3>
<p>Nothing here yet!</p>
<hr>
<strong>Children</strong>
<ol>
<li><a href="/coding-notes/notes/2ka8m9fs91h5ucy4t6hpmt0">Cloud Hardware</a></li>
</ol>
<hr>
<strong>Backlinks</strong>
<ul>
<li><a href="/coding-notes/notes/2cu9kgr61gspzceyaodfek0">Optimization Techniques</a></li>
</ul></div></div><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-0 ant-col-md-6"><div><div class=""><div class="ant-anchor-wrapper dendron-toc" style="max-height:calc(100vh - 64px);z-index:1"><div class="ant-anchor"><div class="ant-anchor-ink"><span class="ant-anchor-ink-ball"></span></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#edge" title="Edge">Edge</a></div></div></div></div></div></div></div></div></div></div></div><div class="ant-divider ant-divider-horizontal" role="separator"></div><footer class="ant-layout-footer" style="padding:0 24px 24px"></footer></main></section></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"note":{"id":"5bixl6kw3cmj3ec9zuvxi1e","title":"Hardware","desc":"Hardware","updated":1713239852304,"created":1710410265296,"custom":{},"fname":"ai.optimization.hardware","type":"note","vault":{"fsPath":".","selfContained":true,"name":"coding-notes"},"contentHash":"451812734608a51ea105ed64c0149deb","links":[{"from":{"fname":"ai.optimization.techniques","id":"2cu9kgr61gspzceyaodfek0","vaultName":"coding-notes"},"type":"backlink","position":{"start":{"line":2,"column":29,"offset":29},"end":{"line":2,"column":66,"offset":66},"indent":[]},"value":"ai.optimization.hardware"}],"anchors":{"edge":{"type":"header","text":"Edge","value":"edge","line":57,"column":0,"depth":3}},"children":["2ka8m9fs91h5ucy4t6hpmt0"],"parent":"za5or2c8fg13zcu51gxpcqs","data":{}},"body":"\u003ch1 id=\"hardware\"\u003eHardware\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#hardware\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003eThis section talks about the different hardware configurations which can be used to run ML models. \u003c/p\u003e\n\u003cp\u003eTo avoid having this section explode to cover every recent version of every piece of hardware from every major vendor, we will try to focus on newer hardware, and on very large models like \u003ca href=\"https://huggingface.co/docs/diffusers/en/using-diffusers/sdxl\"\u003eSDXL\u003c/a\u003e or \u003ca href=\"https://huggingface.co/meta-llama\"\u003eLlama 2\u003c/a\u003e, which are large enough that compute and memory constraints come into play even on new hardware.\u003c/p\u003e\n\u003cp\u003eFor each piece of hardware we will try to address the following questions:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eWhat is its general type? \n\u003cul\u003e\n\u003cli\u003eCPU\u003c/li\u003e\n\u003cli\u003eGPU\u003c/li\u003e\n\u003cli\u003eFPGA\u003c/li\u003e\n\u003cli\u003eSomething else\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eWhat is its architecture? \n\u003cul\u003e\n\u003cli\u003eARM\u003c/li\u003e\n\u003cli\u003ex86\u003c/li\u003e\n\u003cli\u003eSomething else\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eWhere is it available? \n\u003cul\u003e\n\u003cli\u003eCloud\n\u003cul\u003e\n\u003cli\u003eWhich provider?\u003c/li\u003e\n\u003cli\u003eWhich regions?\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eLocal\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eWhat data types are supported? \n\u003cul\u003e\n\u003cli\u003eFLOAT32\u003c/li\u003e\n\u003cli\u003eFLOAT16\u003c/li\u003e\n\u003cli\u003eBFLOAT16\u003c/li\u003e\n\u003cli\u003eINT8\u003c/li\u003e\n\u003cli\u003eOthers\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eAI Acceleration features? \n\u003cul\u003e\n\u003cli\u003eOpenVINO toolkit (Intel)\u003c/li\u003e\n\u003cli\u003eAdvanced Matrix Extensions (AMX - Intel)\u003c/li\u003e\n\u003cli\u003eNeuron (AWS Inferentia SDK)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eWhat does it cost?\n\u003cul\u003e\n\u003cli\u003eHourly\u003c/li\u003e\n\u003cli\u003eYearly (for providers with up-front pricing options)\u003c/li\u003e\n\u003cli\u003eFixed cost (for local hardware)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eHow well does it perform? \n\u003cul\u003e\n\u003cli\u003eInference and fine-tuning speeds\u003c/li\u003e\n\u003cli\u003eInferences-per-second\u003c/li\u003e\n\u003cli\u003eCost-per-inference\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eTo try to keep things organized, we will sort hardware into two general categories:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eCloud: hardware available from major cloud providers.\u003c/li\u003e\n\u003cli\u003eEdge: hardware you run yourself locally.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eThis scheme results in some overlap as most of the hardware available through the major cloud providers will overlap, but it means we get to see differences in pricing and regional availability by provider. It also separates out consumer hardware intended to be used and purchased by individuals from server hardware (which is what the cloud companies buy and/or build). \u003c/p\u003e\n\u003ch3 id=\"edge\"\u003eEdge\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#edge\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003cp\u003eNothing here yet!\u003c/p\u003e\n\u003chr\u003e\n\u003cstrong\u003eChildren\u003c/strong\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"/coding-notes/notes/2ka8m9fs91h5ucy4t6hpmt0\"\u003eCloud Hardware\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003cstrong\u003eBacklinks\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/coding-notes/notes/2cu9kgr61gspzceyaodfek0\"\u003eOptimization Techniques\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","noteIndex":{"id":"9qx3z8b2wfr5chnnb949zv2","title":"Coding Notes","desc":"Notes on writing, fixing, optimizing, and managing code","updated":1713239898794,"created":1710404034956,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":".","selfContained":true,"name":"coding-notes"},"contentHash":"343469aff8d1dd850480e3be33dce7c1","links":[],"anchors":{},"children":["z1cgzhp9dn5hy47dl69sgwr","zrzuso1wjne88yp1b9wtm8v","e1efo5mvaktzbf53sksb0k0","xk249rrm3kfwe5twpc1ouak","2oo9jjnro6kp9228ryfqdgw"],"parent":null,"data":{},"body":"\nWelcome! I keep all my coding notes here. Anything I learn about writing code, testing code, updating code, or optimizing code will go here.\n\nCheck back from time to time for updates. \n"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true,"enableSelfContainedVaults":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":true,"vaultSelectionModeOnCreate":"smart","leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2}},"randomNote":{},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":".","selfContained":true,"name":"coding-notes"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"task":{"name":"task","dateFormat":"y.MM.dd","addBehavior":"asOwnDomain","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"taskCompleteStatus":["done","x"],"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"enableUserTags":true,"enableHashTags":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"enableEditorDecorations":true,"maxPreviewsCached":10,"maxNoteLength":204800,"enableFullHierarchyNoteTitle":false,"enablePersistentHistory":false},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["root"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"Dendron","description":"Personal Knowledge Space"},"github":{"enableEditLink":true,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true,"searchMode":"search","siteUrl":"https://jeremypedersen.github.io","assetsPrefix":"/coding-notes","siteFaviconPath":"favicon.ico","siteIndex":"root"}}},"__N_SSG":true},"page":"/notes/[id]","query":{"id":"5bixl6kw3cmj3ec9zuvxi1e"},"buildId":"jdQmoR0T7zxn3zBS6JrtA","assetPrefix":"/coding-notes","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>