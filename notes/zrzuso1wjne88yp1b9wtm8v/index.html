<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="icon" href="/coding-notes/favicon.ico"/><title>Computer Vision</title><meta name="robots" content="index,follow"/><meta name="googlebot" content="index,follow"/><meta name="description" content="Computer Vision"/><meta property="og:title" content="Computer Vision"/><meta property="og:description" content="Computer Vision"/><meta property="og:url" content="https://jeremypedersen.github.io/coding-notes/notes/zrzuso1wjne88yp1b9wtm8v/"/><meta property="og:type" content="article"/><meta property="article:published_time" content="9/5/2024"/><meta property="article:modified_time" content="9/15/2024"/><link rel="canonical" href="https://jeremypedersen.github.io/coding-notes/notes/zrzuso1wjne88yp1b9wtm8v/"/><meta name="next-head-count" content="14"/><link rel="preload" href="/coding-notes/_next/static/css/b0c7e77ce5f99436.css" as="style"/><link rel="stylesheet" href="/coding-notes/_next/static/css/b0c7e77ce5f99436.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/coding-notes/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/coding-notes/_next/static/chunks/webpack-eed3f0eedf802397.js" defer=""></script><script src="/coding-notes/_next/static/chunks/framework-28c999baf2863c3d.js" defer=""></script><script src="/coding-notes/_next/static/chunks/main-29387b2bb14b1eb7.js" defer=""></script><script src="/coding-notes/_next/static/chunks/pages/_app-dc4bb01b71d58e47.js" defer=""></script><script src="/coding-notes/_next/static/chunks/935-4dee79e80b8641c6.js" defer=""></script><script src="/coding-notes/_next/static/chunks/6-50972def09142ee2.js" defer=""></script><script src="/coding-notes/_next/static/chunks/pages/notes/%5Bid%5D-78d472fa3b924116.js" defer=""></script><script src="/coding-notes/_next/static/jdQmoR0T7zxn3zBS6JrtA/_buildManifest.js" defer=""></script><script src="/coding-notes/_next/static/jdQmoR0T7zxn3zBS6JrtA/_ssgManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><section class="ant-layout" style="width:100%;min-height:100%"><header class="ant-layout-header" style="position:fixed;isolation:isolate;z-index:1;width:100%;border-bottom:1px solid #d4dadf;height:64px;padding:0 24px 0 2px"><div class="ant-row ant-row-center" style="max-width:992px;justify-content:space-between;margin:0 auto"><div style="display:flex" class="ant-col ant-col-xs-20 ant-col-sm-4"></div><div class="ant-col gutter-row ant-col-xs-0 ant-col-sm-20 ant-col-md-20 ant-col-lg-19"><div class="ant-select ant-select-lg ant-select-auto-complete ant-select-single ant-select-allow-clear ant-select-show-search" style="width:100%"><div class="ant-select-selector"><span class="ant-select-selection-search"><input type="search" autoComplete="off" class="ant-select-selection-search-input" role="combobox" aria-haspopup="listbox" aria-owns="undefined_list" aria-autocomplete="list" aria-controls="undefined_list" aria-activedescendant="undefined_list_0" value=""/></span><span class="ant-select-selection-placeholder">For full text search please use the &#x27;?&#x27; prefix. e.g. ? Onboarding</span></div></div></div><div style="display:none;align-items:center;justify-content:center" class="ant-col ant-col-xs-4 ant-col-sm-4 ant-col-md-0 ant-col-lg-0"><span role="img" aria-label="menu" style="font-size:24px" tabindex="-1" class="anticon anticon-menu"><svg viewBox="64 64 896 896" focusable="false" data-icon="menu" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M904 160H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0 624H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0-312H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8z"></path></svg></span></div></div></header><section class="ant-layout" style="margin-top:64px;display:flex;flex-direction:row"><div class="site-layout-sidebar" style="flex:0 0 auto;width:calc(max((100% - 992px) / 2, 0px) + 200px);min-width:200px;padding-left:calc((100% - 992px) / 2)"><aside class="ant-layout-sider ant-layout-sider-dark" style="position:fixed;overflow:auto;height:calc(100vh - 64px);background-color:transparent;flex:0 0 200px;max-width:200px;min-width:200px;width:200px"><div class="ant-layout-sider-children"></div></aside></div><main class="ant-layout-content side-layout-main" style="max-width:1200px;min-width:0;display:block"><div style="padding:0 24px"><div class="main-content" role="main"><div class="ant-row"><div class="ant-col ant-col-24"><div class="ant-row" style="margin-left:-10px;margin-right:-10px"><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-24 ant-col-md-18"><div><h1 id="computer-vision">Computer Vision<a aria-hidden="true" class="anchor-heading icon-link" href="#computer-vision"></a></h1>
<p>Resources related to computer vision. For me this means everything from image processing to stitching panoramas to photogrammetry and even creating and editing NeRF models. </p>
<p>For now it's just sort of a brain dump where I collect tools I want to play with. Here are a few I'm researching now.</p>
<p>Right now the focus is mostly on traditional CV. Things that are more obviously AI driven like text-to-image models will go into the <code>ai.</code> notes tree. </p>
<h2 id="focus-stacking">Focus stacking<a aria-hidden="true" class="anchor-heading icon-link" href="#focus-stacking"></a></h2>
<ul>
<li><a href="https://github.com/PetteriAimonen/focus-stack">focus-stack</a>, plus <a href="https://peterfalkingham.com/2024/04/29/an-excellent-free-and-open-source-focus-stacking-solution/">this blog post</a> talking about how to use it. </li>
</ul>
<h2 id="3d-reconstruction-and-photogrammetry">3D Reconstruction and Photogrammetry<a aria-hidden="true" class="anchor-heading icon-link" href="#3d-reconstruction-and-photogrammetry"></a></h2>
<ul>
<li><a href="https://github.com/micmacIGN/micmac">micmac</a>, open source photogrammetry.</li>
<li><a href="https://github.com/alicevision/Meshroom?tab=readme-ov-file">meshroom</a>, open source 3D reconstruction software</li>
<li>A quick <a href="https://moviola.com/courses/meshroom-survival-guide/">survival guide</a> to using meshroom</li>
<li><a href="https://docs.nerf.studio/">nerfstudio</a> for building NeRFs.</li>
<li><a href="https://www.danielgm.net/cc/">CloudCompare</a> open source software for working with 3D point clouds and meshes.</li>
<li><a href="https://www.meshlab.net/">MeshLab</a> open source system for processing and editing 3D triangular meshes.</li>
<li><a href="https://www.open3d.org/">Open3D</a>, open source software for 3D data processing, with <a href="https://www.open3d.org/docs/release/">documenatation here</a>.</li>
<li><a href="https://www.regard3d.org/index.php/documentation/tutorial">Regard3D</a> open source software to go from a set of images to a 3D model. </li>
<li><a href="http://imagine.enpc.fr/~moulonp/openMVG/index.html">openMVG</a> tool for "multiple view geometry" targeted to developers. Looks like it makes it easy to solve for geometry using 2 to "N" different views of a scene. </li>
<li><a href="https://github.com/cdcseacave/openMVS">openMVS</a> stereo view reconstruction software. Looks like it can do a ton of cool stuff but I'm mostly interested in the ability to do mesh reconstruction (to make 3D models).</li>
<li><a href="https://www.di.ens.fr/pmvs/">PMVS (Patch-based Multi-vew Stereo)</a>, a tool for doing the 3D reconstruction from a set of images. Apparently it is included inside <a href="https://www.di.ens.fr/cmvs/">CVMS (Clustering Views for Multi-vew Stereo)</a>.</li>
</ul>
<p>While looking for open source photogrammetry solutions, I ran across <a href="https://arc-team-open-research.blogspot.com/2016/12/comparing-7-photogrammetry-systems.html">this cool blog post from an archaeology team</a> talking about reconstructions done for scientific purposes. </p>
<p>Wildly enough, the quality of these models can be quite good. Good enough to <a href="https://www.dailymail.co.uk/sciencetech/article-3678651/Animal-avengers-rescue-Adorable-puppy-eat-3D-printed-tooth-replaces-one-broke-chewing.html">print replacement teeth for dogs</a>, at least.</p>
<p>They looked at a couple different solutions and chose openMVS + openMVG as their general favorite.</p>
<p>It looks like for simple 3D reconstructions from a set of photographs Meshlab may also work (not tested in their blog).</p>
<p>As for <strong>sharing the resulting models</strong> it seems <a href="https://www.thingiverse.com/">Thingiverse</a> is the go-to for 3D printing, and <a href="https://sketchfab.com">Sketchfab</a> for general 3D models.  </p>
<p>Apparently <a href="https://threejs.org/examples/#webgl_animation_keyframes">Three.js</a> can also display reconstructions, up to and including animation! </p>
<h2 id="panoramas">Panoramas<a aria-hidden="true" class="anchor-heading icon-link" href="#panoramas"></a></h2>
<ul>
<li><a href="https://hugin.sourceforge.io/">Hugin</a>, which appears to be the leading open source toolkit for making panoramic images, and is based on <a href="https://panotools.sourceforge.net/">Panorama tools</a>. Both seem to be working just fine but are quite old and seem to mostly just be receiving maintenance updates. The releases on the Hugin site indicate that no major new features are being added, but the software is being actively maintained.</li>
<li><a href="https://krupkat.github.io/xpano/">Xpano</a> looks like a simpler alternative to Hugin, will autodetect related images in a folder, stitch them, and export.</li>
</ul>
<h2 id="aiml-stuff">AI/ML Stuff<a aria-hidden="true" class="anchor-heading icon-link" href="#aiml-stuff"></a></h2>
<p>There are some really, really cool demos that mix photography and generative AI. Most of them are hosted on HuggingFace. Here are a couple I've looked at: </p>
<ul>
<li><a href="https://huggingface.co/spaces/TencentARC/InstantMesh">InstantMesh</a> takes a single photo, generates best-guesses for multiple views of the object, and then uses those to create an actual colorized 3D model in OBJ or GLB format.</li>
<li><a href="https://huggingface.co/spaces/MykolaL/StableDesign">StableDesign</a> submit an image of a bare interior and a description of the interior design aesthetic you are interested in, and the system generates a concept image showing the space redesigned to meet your needs.</li>
<li><a href="https://huggingface.co/spaces/Nick088/Stable_Diffusion_Finetuned_Minecraft_Skin_Generator">Minecraft skin generator</a> Use a prompt to generate 3D models which can be used as "skins" for player characters in Minecraft.</li>
<li><a href="https://huggingface.co/multimodalart">multimodalart</a>, a really interesting collection of spaces for generating AI art, including spaces to help you <a href="https://huggingface.co/spaces/multimodalart/lora-ease">easily create and train LoRAs</a> and space to <a href="https://huggingface.co/spaces/multimodalart/face-to-all">re-style selfies</a>.</li>
</ul></div></div><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-0 ant-col-md-6"><div><div class=""><div class="ant-anchor-wrapper dendron-toc" style="max-height:calc(100vh - 64px);z-index:1"><div class="ant-anchor"><div class="ant-anchor-ink"><span class="ant-anchor-ink-ball"></span></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#focus-stacking" title="Focus stacking">Focus stacking</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#3d-reconstruction-and-photogrammetry" title="3D Reconstruction and Photogrammetry">3D Reconstruction and Photogrammetry</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#panoramas" title="Panoramas">Panoramas</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#aiml-stuff" title="AI/ML Stuff">AI/ML Stuff</a></div></div></div></div></div></div></div></div></div></div></div><div class="ant-divider ant-divider-horizontal" role="separator"></div><footer class="ant-layout-footer" style="padding:0 24px 24px"></footer></main></section></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"note":{"id":"zrzuso1wjne88yp1b9wtm8v","title":"Computer Vision","desc":"Computer Vision","updated":1726419927343,"created":1725513444786,"custom":{},"fname":"cv","type":"note","vault":{"fsPath":".","selfContained":true,"name":"coding-notes"},"contentHash":"d4e10c6257125a7dcd9ea81ae68a3ea5","links":[],"anchors":{"focus-stacking":{"type":"header","text":"Focus stacking","value":"focus-stacking","line":14,"column":0,"depth":2},"3d-reconstruction-and-photogrammetry":{"type":"header","text":"3D Reconstruction and Photogrammetry","value":"3d-reconstruction-and-photogrammetry","line":18,"column":0,"depth":2},"panoramas":{"type":"header","text":"Panoramas","value":"panoramas","line":44,"column":0,"depth":2},"aiml-stuff":{"type":"header","text":"AI/ML Stuff","value":"aiml-stuff","line":49,"column":0,"depth":2}},"children":[],"parent":"9qx3z8b2wfr5chnnb949zv2","data":{}},"body":"\u003ch1 id=\"computer-vision\"\u003eComputer Vision\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#computer-vision\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003eResources related to computer vision. For me this means everything from image processing to stitching panoramas to photogrammetry and even creating and editing NeRF models. \u003c/p\u003e\n\u003cp\u003eFor now it's just sort of a brain dump where I collect tools I want to play with. Here are a few I'm researching now.\u003c/p\u003e\n\u003cp\u003eRight now the focus is mostly on traditional CV. Things that are more obviously AI driven like text-to-image models will go into the \u003ccode\u003eai.\u003c/code\u003e notes tree. \u003c/p\u003e\n\u003ch2 id=\"focus-stacking\"\u003eFocus stacking\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#focus-stacking\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/PetteriAimonen/focus-stack\"\u003efocus-stack\u003c/a\u003e, plus \u003ca href=\"https://peterfalkingham.com/2024/04/29/an-excellent-free-and-open-source-focus-stacking-solution/\"\u003ethis blog post\u003c/a\u003e talking about how to use it. \u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"3d-reconstruction-and-photogrammetry\"\u003e3D Reconstruction and Photogrammetry\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#3d-reconstruction-and-photogrammetry\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/micmacIGN/micmac\"\u003emicmac\u003c/a\u003e, open source photogrammetry.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/alicevision/Meshroom?tab=readme-ov-file\"\u003emeshroom\u003c/a\u003e, open source 3D reconstruction software\u003c/li\u003e\n\u003cli\u003eA quick \u003ca href=\"https://moviola.com/courses/meshroom-survival-guide/\"\u003esurvival guide\u003c/a\u003e to using meshroom\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://docs.nerf.studio/\"\u003enerfstudio\u003c/a\u003e for building NeRFs.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.danielgm.net/cc/\"\u003eCloudCompare\u003c/a\u003e open source software for working with 3D point clouds and meshes.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.meshlab.net/\"\u003eMeshLab\u003c/a\u003e open source system for processing and editing 3D triangular meshes.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.open3d.org/\"\u003eOpen3D\u003c/a\u003e, open source software for 3D data processing, with \u003ca href=\"https://www.open3d.org/docs/release/\"\u003edocumenatation here\u003c/a\u003e.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.regard3d.org/index.php/documentation/tutorial\"\u003eRegard3D\u003c/a\u003e open source software to go from a set of images to a 3D model. \u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://imagine.enpc.fr/~moulonp/openMVG/index.html\"\u003eopenMVG\u003c/a\u003e tool for \"multiple view geometry\" targeted to developers. Looks like it makes it easy to solve for geometry using 2 to \"N\" different views of a scene. \u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/cdcseacave/openMVS\"\u003eopenMVS\u003c/a\u003e stereo view reconstruction software. Looks like it can do a ton of cool stuff but I'm mostly interested in the ability to do mesh reconstruction (to make 3D models).\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.di.ens.fr/pmvs/\"\u003ePMVS (Patch-based Multi-vew Stereo)\u003c/a\u003e, a tool for doing the 3D reconstruction from a set of images. Apparently it is included inside \u003ca href=\"https://www.di.ens.fr/cmvs/\"\u003eCVMS (Clustering Views for Multi-vew Stereo)\u003c/a\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWhile looking for open source photogrammetry solutions, I ran across \u003ca href=\"https://arc-team-open-research.blogspot.com/2016/12/comparing-7-photogrammetry-systems.html\"\u003ethis cool blog post from an archaeology team\u003c/a\u003e talking about reconstructions done for scientific purposes. \u003c/p\u003e\n\u003cp\u003eWildly enough, the quality of these models can be quite good. Good enough to \u003ca href=\"https://www.dailymail.co.uk/sciencetech/article-3678651/Animal-avengers-rescue-Adorable-puppy-eat-3D-printed-tooth-replaces-one-broke-chewing.html\"\u003eprint replacement teeth for dogs\u003c/a\u003e, at least.\u003c/p\u003e\n\u003cp\u003eThey looked at a couple different solutions and chose openMVS + openMVG as their general favorite.\u003c/p\u003e\n\u003cp\u003eIt looks like for simple 3D reconstructions from a set of photographs Meshlab may also work (not tested in their blog).\u003c/p\u003e\n\u003cp\u003eAs for \u003cstrong\u003esharing the resulting models\u003c/strong\u003e it seems \u003ca href=\"https://www.thingiverse.com/\"\u003eThingiverse\u003c/a\u003e is the go-to for 3D printing, and \u003ca href=\"https://sketchfab.com\"\u003eSketchfab\u003c/a\u003e for general 3D models.  \u003c/p\u003e\n\u003cp\u003eApparently \u003ca href=\"https://threejs.org/examples/#webgl_animation_keyframes\"\u003eThree.js\u003c/a\u003e can also display reconstructions, up to and including animation! \u003c/p\u003e\n\u003ch2 id=\"panoramas\"\u003ePanoramas\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#panoramas\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://hugin.sourceforge.io/\"\u003eHugin\u003c/a\u003e, which appears to be the leading open source toolkit for making panoramic images, and is based on \u003ca href=\"https://panotools.sourceforge.net/\"\u003ePanorama tools\u003c/a\u003e. Both seem to be working just fine but are quite old and seem to mostly just be receiving maintenance updates. The releases on the Hugin site indicate that no major new features are being added, but the software is being actively maintained.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://krupkat.github.io/xpano/\"\u003eXpano\u003c/a\u003e looks like a simpler alternative to Hugin, will autodetect related images in a folder, stitch them, and export.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"aiml-stuff\"\u003eAI/ML Stuff\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#aiml-stuff\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eThere are some really, really cool demos that mix photography and generative AI. Most of them are hosted on HuggingFace. Here are a couple I've looked at: \u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://huggingface.co/spaces/TencentARC/InstantMesh\"\u003eInstantMesh\u003c/a\u003e takes a single photo, generates best-guesses for multiple views of the object, and then uses those to create an actual colorized 3D model in OBJ or GLB format.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://huggingface.co/spaces/MykolaL/StableDesign\"\u003eStableDesign\u003c/a\u003e submit an image of a bare interior and a description of the interior design aesthetic you are interested in, and the system generates a concept image showing the space redesigned to meet your needs.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://huggingface.co/spaces/Nick088/Stable_Diffusion_Finetuned_Minecraft_Skin_Generator\"\u003eMinecraft skin generator\u003c/a\u003e Use a prompt to generate 3D models which can be used as \"skins\" for player characters in Minecraft.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://huggingface.co/multimodalart\"\u003emultimodalart\u003c/a\u003e, a really interesting collection of spaces for generating AI art, including spaces to help you \u003ca href=\"https://huggingface.co/spaces/multimodalart/lora-ease\"\u003eeasily create and train LoRAs\u003c/a\u003e and space to \u003ca href=\"https://huggingface.co/spaces/multimodalart/face-to-all\"\u003ere-style selfies\u003c/a\u003e.\u003c/li\u003e\n\u003c/ul\u003e","noteIndex":{"id":"9qx3z8b2wfr5chnnb949zv2","title":"Coding Notes","desc":"Notes on writing, fixing, optimizing, and managing code","updated":1713239898794,"created":1710404034956,"custom":{"nav_order":0,"permalink":"/"},"fname":"root","type":"note","vault":{"fsPath":".","selfContained":true,"name":"coding-notes"},"contentHash":"343469aff8d1dd850480e3be33dce7c1","links":[],"anchors":{},"children":["z1cgzhp9dn5hy47dl69sgwr","zrzuso1wjne88yp1b9wtm8v","e1efo5mvaktzbf53sksb0k0","xk249rrm3kfwe5twpc1ouak","2oo9jjnro6kp9228ryfqdgw"],"parent":null,"data":{},"body":"\nWelcome! I keep all my coding notes here. Anything I learn about writing code, testing code, updating code, or optimizing code will go here.\n\nCheck back from time to time for updates. \n"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true,"enableSelfContainedVaults":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":true,"vaultSelectionModeOnCreate":"smart","leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2}},"randomNote":{},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":".","selfContained":true,"name":"coding-notes"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"task":{"name":"task","dateFormat":"y.MM.dd","addBehavior":"asOwnDomain","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"taskCompleteStatus":["done","x"],"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"enableUserTags":true,"enableHashTags":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"enableEditorDecorations":true,"maxPreviewsCached":10,"maxNoteLength":204800,"enableFullHierarchyNoteTitle":false,"enablePersistentHistory":false},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["root"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"Dendron","description":"Personal Knowledge Space"},"github":{"enableEditLink":true,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true,"searchMode":"search","siteUrl":"https://jeremypedersen.github.io","assetsPrefix":"/coding-notes","siteFaviconPath":"favicon.ico","siteIndex":"root"}}},"__N_SSG":true},"page":"/notes/[id]","query":{"id":"zrzuso1wjne88yp1b9wtm8v"},"buildId":"jdQmoR0T7zxn3zBS6JrtA","assetPrefix":"/coding-notes","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>